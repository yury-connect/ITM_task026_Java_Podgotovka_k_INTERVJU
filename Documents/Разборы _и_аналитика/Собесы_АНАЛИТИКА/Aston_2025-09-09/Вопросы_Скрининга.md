# Скрининг в ASTON. Вопросы от HR на первичном собеседовании.

---
## 1.  Что такое **Java Memory Model**? Какие принципы и механизмы лежат в основе ее работы? Приведите примеры проблем, которые могут возникнуть без применения **JMM**, и объясните, как она их решает.

**Java Memory Model (JMM)** — спецификация, определяющая правила видимости изменений памяти между потоками. Гарантирует корректную работу многопоточных программ на любых платформах.

### **Основные принципы и механизмы:**
1. **Happens-Before:** Отношение порядка между операциями. Если A happens-before B, то результат A виден для B.    
2. **Volatile переменные:** Гарантируют видимость изменений и запрещают переупорядочивание операций.    
3. **Синхронизация (synchronized):** Создает точки happens-before. Выход из блока синхронизации делает все изменения видимыми для следующего входа в блок с тем же монитором.    
4. **Final поля:** Гарантируют, что после конструктора их значения видны всем потокам без синхронизации.

### **Проблемы без JMM и решения:**

|Проблема|Пример|Решение через JMM|
|---|---|---|
|**Отсутствие видимости**|Бесконечный цикл из-за закэшированного значения флага.|`volatile` — гарантирует немедленную видимость изменений.|
|**Неправильное упорядочивание**|Получение ссылки на объект, который еще не инициализирован (DCL).|`volatile` — запрещает переупорядочивание операций записи.|
|**Состояние гонки**|Неатомарное изменение shared-переменной.|`synchronized` — обеспечивает атомарность и видимость.|

**Итог:** JMM обеспечивает переносимость и предсказуемость многопоточности через формальные правила happens-before, `volatile` и синхронизацию.

---
## 2. Чем отличаются **конвейерные** (*промежуточные*) и **терминальные** операции *Stream API*? Как эти операции влияют на производительность при обработке потоков данных? Объясните, как порядок применения операций и их тип могут изменяться в зависимости от типа операции.

### **Промежуточные vs. Терминальные операции в Stream API**

#### **1. Отличия**

|Промежуточные (Intermediate)|Терминальные (Terminal)|
|---|---|
|**Ленивые (lazy)** — выполняются только при наличии терминальной операции.|**Энергичные (eager)** — запускают всю цепочку вычислений.|
|Возвращают новый `Stream` (конвейер).|Возвращают результат (void, коллекцию, значение и т.д.).|
|Примеры: `filter()`, `map()`, `sorted()`, `distinct()`.|Примеры: `forEach()`, `collect()`, `count()`, `reduce()`.|

#### **2. Влияние на производительность**
- **Ленивое выполнение**: Промежуточные операции не обрабатывают данные сразу, что позволяет оптимизировать вычисления (например, объединить несколько операций в один проход по данным).    
- **Сокращение элементов**: Операции like `filter()` уменьшают объем данных для последующих шагов, ускоряя обработку.    
- **Stateful-операции**: `sorted()`, `distinct()` требуют полного прохода по данным или сохранения состояния, что может снизить производительность и препятствовать параллелизму.
#### **3. Порядок и эффективность**
- **Порядок операций критичен**: Неправильный порядок может привести к избыточной работе.  
    **Пример**:
```java
list.stream().sorted().filter(x -> x > 100)... // Плохо: сортирует ВСЕ элементы
list.stream().filter(x -> x > 100).sorted()... // Лучше: сортирует только отфильтрованные
```
- **Параллельные потоки**:    
    - `Stateless`-операции (`filter`, `map`) легко параллелятся.        
    - `Stateful`-операции (`sorted`, `distinct`) требуют синхронизации и могут снизить эффективность.

#### **4. Зависимость от типа операции**
- **Stateless** (без состояния): Не зависят от предыдущих элементов (например, `filter`, `map`). Эффективны в параллельных потоках.    
- **Stateful** (с состоянием): Требуют знания о других элементах (например, `sorted`, `distinct`). Могут буферизовать данные и менять порядок выполнения.

**Итог**: Правильный порядок операций и выбор между stateful/stateless напрямую влияет на производительность. Используйте `filter()` и другие сокращающие операции до resource-intensive (например, `sorted()`), чтобы минимизировать объем обрабатываемых данных.

---
## 3. Для чего нужен **spring cloud config**? Как **Spring Cloud Config** интегрируется с различными источниками конфигурации? Как обеспечивается безопасность данных конфигурации?

### **Spring Cloud Config: краткий обзор**
**Назначение:** Централизованное внешнее управление конфигурациями для распределенных систем (*микросервисов*). Позволяет изменять настройки всех сервисов из одного места без передеплоя.

### **Интеграция с источниками конфигурации**
**Config Server** поддерживает несколько **backend**-хранилищ:

1. **Git (по умолчанию):** Наиболее популярный вариант. Хранение конфигов в репозитории (GitLab, GitHub, etc.). Поддержка версионности, веток, тегов.
    
2. **Файловая система (Local):** Хранение конфигов на диске сервера. Для тестирования или простых сценариев.
    
3. **Vault:** Специализированное хранилище для секретов (пароли, токены). Обеспечивает высокий уровень безопасности, динамическое создание секретов.
    
4. **JDBC:** Хранение конфигов в реляционной БД.
    
5. **Composite:** Комбинирование нескольких источников одновременно.

### **Обеспечение безопасности данных**
1. **Шифрование / Дешифрование:**    
    - Config Server может **шифровать** чувствительные данные (пароли, токены) в конфигурационных файлах.
        
    - Используются симметричные или асимметричные ключи (JCE).
        
    - Данные в хранилище передаются в зашифрованном виде (`{cipher}...`), а клиенты автоматически их расшифровывают.
        
2. **Защита транспортного уровня (HTTPS):** Обязательное использование SSL/TLS для шифрования трафика между Config Server и клиентами.
    
3. **Аутентификация и авторизация:**    
    - **Security на самом Config Server:** Защита endpoints с помощью Spring Security (базовая аутентификация, OAuth2, JWT).
        
    - **Использование Vault:** Vault сам по себе имеет сложные механизмы аутентификации (токены, AppRole) и детальный контроль доступа.
        
4. **Минимизация прав доступа:** Настройка прав доступа к репозиторию (Git) только на чтение для сервера и ограничение круга лиц, кто может в него писать.

---
## 4. Почему у **prototype** бинов не вызывается **destroy** метод в *Spring*'e? Какие особенности жизненного цикла бинов в контексте управляемых *Spring* контейнером необходимо учитывать при использовании прототипов? Как это влияет на управление ресурсами и их очистку?

**1. Почему не вызывается destroy-метод?**
- Spring управляет **полным жизненным циклом** только для бинов с областью видимости **singleton**.    
- Для **prototype** Spring выполняет только **инициализацию** (вызывает `@PostConstruct` / `afterPropertiesSet()`), передаёт объект клиенту и **теряет контроль** над ним. Контейнер больше не отслеживает его состояние и не вызывает метод уничтожения.

**2. Особенности жизненного цикла prototype-бинов:**
- **Создание:** Новый экземпляр создаётся при каждом запросе (через `getBean()` или инъекцию).    
- **Инициализация:** Вызываются методы инициализации.    
- **Управление:** После создания и внедрения ответственность за bean (включая его уничтожение) переходит к клиенту (другому бину или коду, который его запросил).

**3. Влияние на управление ресурсами и очистку:**
- **Проблема:** Риск **утечки ресурсов** (открытые соединения с БД, файловые дескрипторы), которые не будут автоматически закрыты контейнером.
- **Решение:** Клиентский код, использующий prototype-bean, **сам обязан** освобождать ресурсы.    
    - Реализовать кастомный метод очистки и явно вызывать его.        
    - Использовать шаблон **callback-интерфейса**, где Spring-бин уведомляет клиента о необходимости cleanup.        
    - Использовать `ObjectFactory` или `Provider` для точечного создания и управления временем жизни бина внутри клиента.

---
## 5. Чем отличается **spring boot starter** от обычной зависимости? В чём заключается роль стартера для упрощения настройки, и как он помогает интегрировать зависимости и конфигурацию?

**1. Отличие от обычной зависимости:**
- **Обычная зависимость** — это <u>одна библиотека</u> *(jar-файл)*.    
- **Spring Boot Starter** — это **мета-зависимость**, которая сама по себе не содержит кода, но описывает набор совместимых друг с другом обычных зависимостей (транзитивных), необходимых для использования определенной технологии (например, Spring Web, JPA, Security).

**2. Роль стартера:**
- **Упрощение настройки:** Стартеры автоматически настраивают бины с разумными значениями по умолчанию (*Auto-Configuration*).    
- **Управление зависимостями:** Избавляют разработчика от ручного подбора и разрешения конфликтов версий совместимых библиотек.    
- **Предоставление готовой конфигурации:** Содержат `META-INF/spring.factories` с указанием классов автоматической конфигурации, которые подключаются при наличии стартера в classpath.

**3. Как помогает интегрировать:**
- **Добавление одной зависимости** (стартера) подключает сразу **все необходимое** для работы с технологией.    
- **Автоконфигурация** на основе условий (например, `@ConditionalOnClass`) автоматически создает и настраивает бины, если нужные классы есть в classpath.    
- **Свойства** для тонкой настройки через `application.properties/yaml` унифицированы и стандартизированы для всех стартеров.

**Итог:** Стартер — это ключевой механизм **Spring Boot** для обеспечения **convention over configuration**, радикально сокращающий время на настройку проекта.

---
## 6. Приведите пример когда не нужно использовать микросервисную архитектуру. Назовите пару причин. Почему в этих случаях лучше выбрать другие подходы.

**Пример:** Небольшие проекты, стартапы, внутренние утилиты, монолиты с низкой нагрузкой и простой логикой.

**Причины, почему не нужно использовать микросервисы:**
1. **Сложность разработки и поддержки (Complexity Overkill):
    - **Почему:** Микросервисы требуют orchestration (Kubernetes), мониторинга, трассировки, CI/CD для множества репозиториев.
    - **Чем заменить:** **Монолит** проще разрабатывать, дебажить и деплоить на ранних этапах.
    
2. **Нет бизнес-потребности (*No Clear Boundaries*):
    - **Почему:** Если доменная модель тесно связана и её нельзя разбить на независимые контексты.
    - **Чем заменить:** **Модульный монолит** (Modular Monolith) с четким разделением на модули внутри одной кодовой базы.
    
3. **Производительность и транзакции (*Distributed System Challenges*):**    
    - **Почему:** Межсервисное взаимодействие (HTTP/gRPC) медленнее внутрипроцессного. Нет простого способа обеспечить распределенные транзакции (ACID).
    - **Чем заменить:** **Монолит** или **монолит с модулями** для гарантий согласованности данных и низкой задержки.

**Главный вывод:** Микросервисы — это архитектура для **масштабирования команд и сложных систем**, а не для технологического тренда. Они добавляют огромную операционную сложность, которая оправдана только тогда, когда бизнес-требования перевешивают затраты на её поддержание.

---
## 7. Какие проблемы могут возникнуть при создании индекса на каждый столбец SQL таблицы? Как это влияет на производительность? Укажите, какие аспекты следует учитывать при проектировании индексов для таблицы с высокой нагрузкой и разнообразными типами запросов.

**1. Проблемы индексации каждого столбца:**
- **Замедление операций DML (INSERT, UPDATE, DELETE):** Каждый индекс требует обновления при изменении данных. Чем больше индексов, тем медленнее запись.
    
- **Увеличение размера БД:** Индексы занимают место на диске, иногда больше, чем сама таблица.
    
- **Избыточность:** Многие индексы могут никогда не использоваться оптимизатором, бесполезно тратя ресурсы.
    
- **Конкуренция за ресурсы:** При высокой нагрузке множество индексов усиливают блокировки и contention.

**2. Влияние на производительность:**
- **Чтение (SELECT):** Может ускориться для простых запросов, но замедлиться для сложных из-за стоимости выбора и использования индексов.
    
- **Запись (INSERT/UPDATE/DELETE):** Существенно замедляется.

**3. Аспекты проектирования для высоконагруженных таблиц:**
1. **Анализ запросов:** Индексируйте только те столбцы, которые участвуют в `WHERE`, `JOIN`, `ORDER BY`.
    
2. **Составные индексы:** Создавайте их для частых комбинаций условий. Учитывайте порядок столбцов.
    
3. **Селективность:** Индексируйте высокоселективные столбцы (с большим количеством уникальных значений).
    
4. **Мониторинг:** Удаляйте неиспользуемые индексы и добавляйте нужные на основе планов запросов.
    
5. **Баланс:** Найдите компромисс между скоростью чтения и скоростью записи.

---
## 8. Какие основные проблемы решает **Нормализация SQL** базы данных и какие принципы лежат в основе процесса нормализации? Как Нормализация влияет на Целостность данных, производительность и масштабируемость базы данных?

**1. Основные проблемы, которые решает:**
- **Избыточность данных:** Исключает дублирование информации (например, одни и те же данные хранятся в нескольких местах).
    
- **Аномалии обновления (Update Anomalies):** Риск того, что при изменении данных в одном месте, их копии в других местах останутся неизменными.
    
- **Аномалии удаления (Delete Anomalies):** Риск случайной потери данных при удалении связанной записи.
    
- **Аномалии добавления (Insert Anomalies):** Невозможность добавить одни данные без наличия других.

**2. Основные принципы (Нормальные формы):**  
Процесс постепенного приведения таблиц к стандартным формам:
- **1NF:** Атомарность данных (каждое поле содержит только одно значение).    
- **2NF:** Отсутствие неключевых атрибутов, зависящих от части составного ключа.    
- **3NF:** Отсутствие транзитивных зависимостей (неключевые атрибуты зависят только от первичного ключа).    
- **BCNF:** Усиленная 3NF для исключения всех нетривиальных зависимоств.

**3. Влияние нормализации:**

|Аспект|Влияние|
|---|---|
|**Целостность**|**Повышает.** Упрощает поддержание целостности за счет уменьшения избыточности и использования внешних ключей.|
|**Производительность (Чтение)**|**Может снизить.** Сложные запросы с множеством JOINs выполняются дольше.|
|**Производительность (Запись)**|**Повышает.** Ускоряет операции INSERT/UPDATE/DELETE due to меньшего объема данных для изменения.|
|**Масштабируемость**|**Повышает.** Четкая структура и отсутствие дубликатов облегчают масштабирование и партиционирование.|

**Итог:** Нормализация — это компромисс. Она критически важна для целостности и эффективности записи, но может требовать денормализации для ускорения сложных запросов на чтение в высоконагруженных системах.

---
## 9. Какие основные проблемы решает Нормализация SQL базы данных, и какие принципы лежат в основе процесса нормализации? Как Нормализация влияет на Целостность данных, производительность и масштабируемость базы данных?

### **Нормализация БД**

**1. Основные проблемы, которые решает:**
- **Избыточность данных:** Устраняет дублирование информации.
    
- **Аномалии обновления:** Риск несовпадения данных при изменении в одном месте и отсутствии изменений в дубликатах.
    
- **Аномалии удаления:** Потеря данных при удалении связанной записи.
    
- **Аномалии добавления:** Невозможность добавить данные без наличия связанной информации.

**2. Основные принципы (Нормальные формы):**  
Процесс приведения таблиц к стандартным формам:
- **1NF:** Атомарность данных (каждое поле содержит одно значение).    
- **2NF:** Отсутствие зависимостей неключевых атрибутов от части составного ключа.    
- **3NF:** Отсутствие транзитивных зависимостей (неключевые атрибуты зависят только от первичного ключа).    
- **BCNF:** Усиленная 3NF для исключения всех нетривиальных зависимостей.

**3. Влияние нормализации:**

|Аспект|Влияние|
|---|---|
|**Целостность**|**Повышает.** Упрощает поддержание целостности за счет уменьшения избыточности и использования внешних ключей.|
|**Производительность (Чтение)**|**Может снизить.** Сложные запросы с множеством JOINs выполняются дольше.|
|**Производительность (Запись)**|**Повышает.** Ускоряет операции INSERT/UPDATE/DELETE due to меньшего объема данных для изменения.|
|**Масштабируемость**|**Повышает.** Четкая структура и отсутствие дубликатов облегчают масштабирование и партиционирование.|

**Итог:** Нормализация — это *компромисс*. Она критически важна для целостности и эффективности записи, но может требовать денормализации для ускорения сложных запросов на чтение в высоконагруженных системах.

---
## 10. Как в **кафка** можно записать **все сообщения**, к примеру, по одному пользователю, **в одну партицию**, чтобы прочитать их одним консумером?  С условием, что мы пишем данные в топик с тремя партициями (*относится только к кафке*). Объясните, как работает механизм распределения сообщений по партициям и как можно использовать ключи для обеспечения правильного распределения данных.

### **Управление распределением сообщений в Kafka**

#### **1. Механизм распределения сообщений по партициям**
- Если **ключ сообщения (key) = `null`**:  
    Сообщения распределяются по партициям **циклически (round-robin)**. Это обеспечивает балансировку нагрузки, но порядок сообщений не гарантируется.
    
- Если **ключ указан**:  
    Kafka вычисляет хэш ключа (*например, с помощью алгоритма `murmur2`*) и использует его для определения целевой партиции:  
    `partition = hash(key) % number_of_partitions`  
    **Все сообщения с одинаковым ключом попадают в одну и ту же партицию.**

#### **2. Как записать все сообщения по пользователю в одну партицию?**
- Используйте **ID пользователя в качестве ключа** сообщения.  
    Пример (Java):
```java
ProducerRecord<String, String> record = new ProducerRecord<>(
    "user_events_topic", 
    userId,  // Ключ = ID пользователя
    eventData  // Значение
);
producer.send(record);
```
   Все сообщения с одинаковым `userId` будут направлены в одну партицию.

#### **3. Преимущества подхода**
- **Сохранение порядка**: Все события пользователя обрабатываются **консумером одной партиции** строго по порядку.
    
- **Упрощение обработки**: Консумер может агрегировать данные пользователя без необходимости синхронизации между другими консумерами.

#### **4. Важные нюансы**
- **Балансировка нагрузки**: Если некоторые пользователи генерируют много данных, их партиции могут стать "горячими". Необходимо следить за распределением нагрузки.
    
- **Количество партиций**: Фиксируется при создании топика. Изменение количества партиций нарушит соответствие `hash(key) % partitions`.
    
- **Кастомный партиционер**: При необходимости можно реализовать собственный алгоритм распределения, указав его в настройках продюсера (`partitioner.class`).

#### **5. Итог**
Использование **ключа = ID пользователя** гарантирует, что все сообщения пользователя попадут в одну партицию и будут потреблены одним консумером, что обеспечивает порядок и консистентность обработки.

---

