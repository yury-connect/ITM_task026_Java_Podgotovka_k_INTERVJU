# Map / `HashMap` — сначала просто, затем детально 🔥

---
## Простыми словами (*1–2 предложения*)

`HashMap` — реализация `Map`, которая хранит пары ключ→значение в массиве «бакетов». Для быстрого доступа ключ хэшируется; обычно операции `get`/`put` — **O(1)** в среднем. При коллизиях элементы в бакете хранятся в списке или (с Java 8) в красно-чёрном дереве — что гарантирует **O(log n)** в худшем случае. ✅

---
# Детально — как реализовано и почему это важно

## Основные поля (идея)
- `transient Node<K,V>[] table;` — основной массив бакетов (каждый бакет — ссылка на `Node`/`TreeNode`).    
- `transient int size;` — число записей.    
- `int threshold;` — порог для ресайза = `capacity * loadFactor`.    
- `final float loadFactor;` — коэффициент заполнения (по умолчанию **0.75f**).    
- `transient int modCount;` — счётчик модификаций (fail-fast итераторы).    

---
## Node / структура хранения

Упрощённо:
```java
static class Node<K,V> implements Map.Entry<K,V> {
  final int hash;
  final K key;
  V value;
  Node<K,V> next; // ссылка на следующий в бакете (в виде списка)
}
```

В Java 8 при «переполнении» списка на бакете он преобразуется в `TreeNode` (RB-дерево).

---
## Как считается индекс (hash & index)

1. `int h = key == null ? 0 : spread(key.hashCode());`
    
2. `index = (n - 1) & h` — где `n` — текущая ёмкость (`table.length`).  
    `spread` — функция, которая перемешивает биты:    

```java
static final int spread(int h) { return h ^ (h >>> 16); }
```

Почему: чтобы высокие биты `hashCode()` тоже влияли на индекс при малых `n`.

---
## Capacity, loadFactor, threshold

- `capacity` = длина массива `table` (всегда степень двойки).
    
- `loadFactor` (по умолчанию 0.75) балансирует между памятью и числом реконструкций (resize).
    
- `threshold = capacity * loadFactor` — при достижении его таблица **увеличивается в 2 раза** (resize), и все записи ре-хэшируются.    

---
## put(K,V) — шаги (упрощённо)

1. Если `table == null` — инициализировать (DEFAULT_CAPACITY = 16).
    
2. Вычислить `hash` и `index`.
    
3. Если в `table[index]` пусто → поместить новый `Node`.
    
4. Иначе — пройти по цепочке:
    
    - если встретили `key.equals` → заменить `value`.
        
    - иначе добавить в конец списка.
        
5. Если длина списка > `TREEIFY_THRESHOLD` (8) → превращаем в дерево (`treeifyBin`) **если** `capacity >= MIN_TREEIFY_CAPACITY` (64), иначе сначала делаем `resize`.
    
6. `size++`, возможно `resize()` если `size > threshold`.    

---
## get(K) — шаги

1. Если `table == null` → null.
    
2. Вычислить `hash` и `index`.
    
3. Пройти через `Node`/`TreeNode` в этом бакете: сравнивать `hash` и `equals(key)`.
    
4. Вернуть найденное `value` или `null`.    

Среднее время — O(1) (маленькое число элементов в бакете). Worst-case: O(n) (один бакет) → но деревья ограничивают O(log n).

---
## Коллизии и treeify (Java 8+)

- `TREEIFY_THRESHOLD = 8` — при ≥8 элементов в бакете пытаются сделать RB-дерево.
    
- `MIN_TREEIFY_CAPACITY = 64` — если текущая capacity < 64, вместо treeify сначала **resize** (чтобы снизить плотность и разбить цепочки).
    
- После treeify дальнейшие операции в этом бакете — логарифмические.    

---
## Ресайз (rehash)

- При `resize()` capacity удваивается, создаётся новый массив, все узлы перераспределяются (новый индекс = `hash & (newCap-1)`).
    
- Ресайз дорог по CPU и аллокациям — поэтому лучше правильно задавать `initialCapacity` если ожидаем много элементов.    

---
## Итераторы и модификации

- `modCount` инкрементируется при structural modifications (put/remove/resize).
    
- Итераторы — **fail-fast**: если `modCount` изменился во время итерации, `ConcurrentModificationException` бросается.    

---
## Null key / null values

- `HashMap` разрешает **один** `null`-ключ (хранится в `table[0]` с `hash = 0`) и любое количество `null`-значений.

---
## Производительность и рефакторинг

- В среднем `get/put/remove` — O(1).
    
- В худшем — O(n), но Java 8+ снижает это до O(log n) при больших коллизиях.
    
- Чтобы избежать частых ресайзов: `initialCapacity = expectedSize / loadFactor + 1`.
    
- Для детерминированного порядка используйте `LinkedHashMap` (связный список по вставке/по доступу).

---
## Потокобезопасность

- `HashMap` **не потокобезопасна**: concurrent модификации могут привести к некорректной структуре (в старых версиях — даже к бесконечному циклу).
    
- Для concurrent use: `ConcurrentHashMap` — другой алгоритм (без блокировки всей таблицы), атомарные операции, нет `null` ключей/значений и другая семантика.

Кратко про `ConcurrentHashMap` (**`Java 8+`**):
- использует CAS и synchronized только на отдельных биндах; поддерживает lock-free reads; для heavy writes использует bin-locking / tree bins; гарантирует более безопасную параллельную работу.

---
## Важные практические нюансы / ошибки

- **Mutable key**: если ключ меняет `hashCode()`/`equals()` после вставки — элемент «потерян» (get не найдёт).
    
- **Не задавать слишком маленький loadFactor** — больше памяти. Слишком большой — больше коллизий → медленнее.
    
- **Не полагаться на порядок** — `HashMap` не гарантирует порядок.
    
- **ConcurrentModificationException** — следи за итерацией и модификациями.
    
- **Большие значения** → задавай initialCapacity, чтобы избежать ресайза в рабочем сценарии.    

---
## Внутренние константы (важно запомнить)

- `DEFAULT_INITIAL_CAPACITY = 16`
    
- `MAXIMUM_CAPACITY = 1 << 30`
    
- `DEFAULT_LOAD_FACTOR = 0.75f`
    
- `TREEIFY_THRESHOLD = 8`
    
- `UNTREEIFY_THRESHOLD = 6`
    
- `MIN_TREEIFY_CAPACITY = 64`    

---
## Краткая демонстрация псевдо-кода `put`

```java
int hash = spread(key.hashCode());
int i = (table.length - 1) & hash;
if (table[i] == null)
    table[i] = new Node(hash, key, value, null);
else {
    Node<K,V> e = table[i];
    while (true) {
        if (e.hash == hash && Objects.equals(e.key, key)) { e.value = value; break; }
        if (e.next == null) { e.next = new Node(hash, key, value, null); break; }
        e = e.next;
    }
    if (bucketSize >= TREEIFY_THRESHOLD) treeify(i);
}
if (++size > threshold) resize();
```

---
## Что сказать на собеседовании (*короткий ответ*)

- `HashMap` — массив бакетов + связные списки (или RB-деревья). Индекс вычисляется как `hash ^ (hash>>>16)` затем `& (capacity-1)`. Default capacity 16, loadFactor 0.75, resize ×2. Коллизии → список → при длинных цепочках (≥8) → дерево. Не потокобезопасна; для concurrency — `ConcurrentHashMap`.

---
# Визуальная схема (array → buckets → chains/trees)
```rust
table (Node[] array)
index: 0    1    2    3    4    5    6 ...
       ↓    ↓    ↓    ↓    ↓    ↓    ↓
       ┌────────┐
0  ->  │ null   │
       └────────┘

1  ->  ┌────────┐
       │ NodeA ─► next -> NodeB ─► next -> NodeC        (链表 / linked list)
       └────────┘

2  ->  ┌────────────────────────────────────────────────┐
       │ TreeBin(root)  ── (TreeNode key/hashes в RB-дереве)  (treeified bin)
       └────────────────────────────────────────────────┘

3  ->  ┌────────┐
       │ NodeD  │
       └────────┘

4  ->  ┌────────────────┐
       │ ForwardingNode │   (в процессе resize — указывает на новую таблицу)
       └────────────────┘
```
- `table` — основной массив бакетов.    
- В бакете либо `null`, либо `Node` (голова цепочки), либо специальный `TreeBin`/`TreeNode`, либо `ForwardingNode` во время ресайза.    
- При коллизиях элементы идут в цепочку (`next`) → при накоплении элементов (threshold) цепочка преобразуется в RB-дерево (`TreeBin`/`TreeNode`) для O(log n).

---
# ConcurrentHashMap internals — понятными словами, но технически

## Основные структуры
- `volatile Node<K,V>[] table` — основная таблица.
    
- `static class Node<K,V> { final int hash; final K key; volatile V val; volatile Node<K,V> next; }` — базовая ячейка (immutable hash/key, volatile value/next).
    
- `TreeNode` / `TreeBin` — классы для представления «дерева в бакете» (красно-чёрное дерево).
    
- `ForwardingNode` — маркер/указатель во время `resize`: старый слот указывает на новую таблицу.
    
- `baseCount` + `CounterCells[]` — счётчики размера, сделанные по идее LongAdder (CAS + cells) для уменьшения contention.    

## CAS (compare-and-swap)
- Основной механизм синхронизации — **CAS** (Unsafe.compareAndSwapObject/Long) на:    
    - элемент массива `table[i]` (вставка в пустой слот),        
    - поле `next` иногда при конкурентных модификациях,        
    - `baseCount` и элементы `CounterCells`.        
- CAS позволяет неблокирующим образом установить ссылку на новый `Node` если слот пуст. Это даёт низкоуровневую lock-free fast-path для многих операций.    

## Операции: put / get / compute

### get(K)
- Читается `table` (volatile), берётся `Node` по индексу и прогоняется цепочка/дерево, сравнивая `hash` и `equals`.    
- **Без блокировок** (lock-free read). Если встретили `ForwardingNode` — следуем в новую таблицу (в процессе resize). Очень быстрый путь для чтения.    

### put(K,V)
1. Вычисляем индекс.    
2. Если `table[i] == null` — пытаемся вставить новым Node через **CAS**: `casTabAt(tab,i,null,newNode)` → успех → done.    
3. Если слот занят:    
    - если это `TreeBin` → синхронно модифицируем дерево (TreeBin защищён внутренним lock/synchronized).        
    - если это цепочка → при небольшой конкуренции мы синхронно (synchronized на голову бакета) или используем CAS-цепочку / спин — реализация оптимизирована: сначала пробуем проверить отсутствие ключа и append; если длина цепочки превышает threshold → `treeifyBin` (дерево) или сначала `resize` если capacity маленький.        
4. Обновление счётчиков размера — CAS на `baseCount`, при contention — используем `CounterCells` (sharded counters).

### resize()
- При достижении `threshold` запускается расширение таблицы (умножение capacity ×2). Resize выполняется параллельно: любой поток, обнаруживший необходимость, может помогать переносить диапазоны бакетов в новую таблицу.    
- В старой таблице на уже перенесённые слоты ставится `ForwardingNode`, чтобы другие потоки перенаправлялись в новую таблицу. Это кооперативный алгоритм, избегает глобальной блокировки.    

## TreeBin / treeify
- При длинных цепочках (обычно ≥8) выполняется `treeifyBin` — превращение списка в красно-чёрное дерево (`TreeNode`) **только если** таблица достаточно большая (`MIN_TREEIFY_CAPACITY`, иначе сначала resize).    
- Дерево даёт O(log n) поиск/вставку в бакете. Модификации дерева выполняются под локом (synchronized внутри TreeBin) — это локальная блокировка на конкретном бакете.    

## Блокировки и синхронизация
- Чтения — не блокируют.    
- Модификации:    
    - fast-path: CAS вставка в пустой слот — lock-free.        
    - при коллизиях и для дерева — локальные synchronized (на TreeBin или head node) используются. Это ограничивает область блокировки до одного бакета (а не всей таблицы).        
- Resize синхронизирован кооперативно через ForwardingNode + CAS + перетаскивание чанков, без глобальной блокировки.    

## Size / count
- Прямой `size` поддерживается через `baseCount` и `CounterCells[]` (аналог LongAdder): при большой конкуренции потоки пишут в разные ячейки счётчиков, чтобы не контендиться на одной CAS. Для получения итогового размера — суммируются base+cells.    

## Специальные узлы
- `ReservationNode` — используется для операций типа `computeIfAbsent` как метка «в процессе вычисления», чтобы другие потоки ждали/обходили.    

---
# Почему ConcurrentHashMap быстрый/масштабируемый

- Чтения: почти полностью lock-free (volatile + plain traversals).
    
- Записи: большинство операций используют CAS в пустой бакет (обычная ситуация при равномерном распределении ключей).
    
- Локализация блокировок: при коллизиях блокируется только конкретный бакет/дерево, а не вся таблица.
    
- Шардинг счётчика (`CounterCells`) уменьшает contention при частых insert/delete.
    
- Параллельный resize: несколько потоков помогают переносить, нет долгой глобальной остановки.    

---
# Практические советы и поведение в коде

- Не используйте `null` ключи/значения — `ConcurrentHashMap` их не поддерживает.
    
- Идеально подходит для высококонкурентных read-mostly сценариев; для очень горячих write-heavy нагрузок следите за contention и коллизиями (хороший хэш!).
    
- При реконструкции больших объектов/цензурировании частых ресайзов — задавайте подходящий `initialCapacity` и `loadFactor` заранее.    

---
